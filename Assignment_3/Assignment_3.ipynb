{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1667347568673,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "-lduQvi880pL",
    "outputId": "8b72812e-b7ee-4ce5-9fad-c3659dabeedb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:33:45.351976: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-01 21:33:45.354744: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-01 21:33:45.354752: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorboard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "doHQpg5c8wu_"
   },
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 434,
     "status": "ok",
     "timestamp": 1667347570092,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "Vmodq7ol8kYE"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "train_images = train_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 44687,
     "status": "ok",
     "timestamp": 1667347616499,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "Jdj2ozeb9gYS",
    "outputId": "57756ea9-0e37-4494-abd1-89f2cf838ccc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2,5)\n",
    "ax = ax.flatten()\n",
    "for i in range(10):\n",
    "    im_idx = np.argwhere(train_labels == i)[0]\n",
    "    plottable_image = np.reshape(train_images[im_idx], (28, 28))\n",
    "    ax[i].imshow(plottable_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1667347616500,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "_2zasDso9uPE",
    "outputId": "e09a9571-b884-4833-e26b-c56731eefb14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_labels[100])\n",
    "\n",
    "tf.keras.utils.to_categorical(train_labels)[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPr0oYMlvC1U"
   },
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1667347681290,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "eAISjA_e9tL-",
    "outputId": "0ee8f02d-b52d-44b1-8133-3adb49f68a1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 8)         296       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 22, 22, 12)        876       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 20, 20, 16)        1744      \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 18, 18, 20)        2900      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 24)        4344      \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 14, 14, 28)        6076      \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 12, 12, 32)        8096      \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 10, 10, 36)        10404     \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 40)          13000     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                25610     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 73,386\n",
      "Trainable params: 73,386\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 21:34:01.094425: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-11-01 21:34:01.094484: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (alberto-Inspiron): /proc/driver/nvidia/version does not exist\n",
      "2022-11-01 21:34:01.095718: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "model1 = keras.models.Sequential([\n",
    "        keras.Input(shape=(28,28,1)),\n",
    "        keras.layers.Conv2D(4, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(12, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(20, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(24, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(28, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(36, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(40, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1667347684374,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "5qyC5_TDqoaH"
   },
   "outputs": [],
   "source": [
    "model1.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "K.set_value(model1.optimizer.learning_rate, 0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9yI7G_KAIO1",
    "outputId": "0acba4bc-cfed-4229-b989-0457b87c3c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0612 - accuracy: 0.9813\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 18s 10ms/step - loss: 0.0583 - accuracy: 0.9815\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0567 - accuracy: 0.9827\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0541 - accuracy: 0.9827\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 0.0522 - accuracy: 0.9840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8c4907160>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model.\n",
    "model1.fit(\n",
    "    train_images,\n",
    "    train_labels, \n",
    "    batch_size=32,\n",
    "    epochs=5, \n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9L2tB8Z0h7CZ"
   },
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will summarize the results based on the optimizer method\n",
    "\n",
    "##### Adam:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 6.490649223327637 ---- Test accuracy: 0.9702000021934509\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 9.572504997253418 ---- Test accuracy: 0.9664000272750854\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 194.7186737060547 Test accuracy: 0.13249999284744263\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 185.1067657470703 ---- Test accuracy: 0.14560000598430634\n",
    "\n",
    "\n",
    "##### SGD:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 209.14405822753906 ---- Test accuracy: 0.1467999964952469\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 184.36209106445312 ---- Test accuracy: 0.13920000195503235\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 159.16867065429688 ---- Test accuracy: 0.1468999981880188\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 187.08892822265625 ---- Test accuracy: 0.15070000290870667\n",
    "\n",
    "\n",
    "##### RMSProp:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 810.2504272460938 ---- Test accuracy: 0.15449999272823334\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 1778.3662109375 ---- Test accuracy: 0.1468999981880188\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 2353.105712890625 ---- Test accuracy: 0.14659999310970306\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 2807.159423828125 ---- Test accuracy: 0.15719999372959137\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5585,
     "status": "ok",
     "timestamp": 1667345193106,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "20VyDP0GAg7F",
    "outputId": "935bf132-e706-4ebe-958a-74a5c160dfa3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 2335.8582 - accuracy: 0.1546\n",
      "Test loss: 2335.858154296875\n",
      "Test accuracy: 0.15459999442100525\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "score = model1.evaluate(test_images, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXOcdrqjAhBR"
   },
   "source": [
    "#### Final Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_jBwK0jh8As"
   },
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28018,
     "status": "ok",
     "timestamp": 1667345674595,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "B9QETp4Mh7bd",
    "outputId": "85192168-dbd9-4cc0-e8f1-0601097413f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_10 (Conv2D)          (None, 26, 26, 40)        400       \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 36)        12996     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 22, 22, 32)        10400     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 20, 20, 28)        8092      \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 18, 18, 24)        6072      \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 16, 16, 20)        4340      \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 14, 14, 16)        2896      \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 12)        1740      \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 10, 10, 8)         872       \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 8, 8, 4)           292       \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,670\n",
      "Trainable params: 50,670\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "model2 = keras.models.Sequential([\n",
    "        keras.Input(shape=(28,28,1)),\n",
    "        keras.layers.Conv2D(40, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(36, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(28, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(24, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(20, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(12, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(4, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "3tQ7I37Bh-Py"
   },
   "outputs": [],
   "source": [
    "model2.compile(\n",
    "    optimizer='RMSprop',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "K.set_value(model2.optimizer.learning_rate, 0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "qJ4K2vVriWut",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 0.0063 - accuracy: 0.9984\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 43s 46ms/step - loss: 0.0039 - accuracy: 0.9989\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 40s 42ms/step - loss: 0.0034 - accuracy: 0.9991\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 40s 42ms/step - loss: 0.0042 - accuracy: 0.9989\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 44s 46ms/step - loss: 0.0037 - accuracy: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe7f4ed9ea0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model.\n",
    "model2.fit(\n",
    "    train_images,\n",
    "    train_labels, \n",
    "    batch_size=64,\n",
    "    epochs=5, \n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will summarize the results based on the optimizer method\n",
    "\n",
    "##### Adam:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 6.4124321937561035 ---- Test accuracy: 0.9718999862670898\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 8.255528450012207 ---- Test accuracy: 0.9638000130653381\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 16.019819259643555 ---- Test accuracy: 0.9602000117301941\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 14.98194408416748 ---- Test accuracy: 0.9707000255584717\n",
    "\n",
    "\n",
    "##### SGD:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 11.841575622558594 ---- Test accuracy: 0.979200005531311\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 12.16141414642334 ---- Test accuracy: 0.979200005531311\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 12.396894454956055 ---- Test accuracy: 0.9793000221252441\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 12.465036392211914 ---- Test accuracy: 0.979200005531311\n",
    "\n",
    "\n",
    "##### RMSProp:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 15.826443672180176 ---- Test accuracy: 0.9598000049591064\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 36.027587890625 ---- Test accuracy: 0.9584000110626221\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 37.842185974121094 ---- Test accuracy: 0.9768000245094299\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 37.7193717956543 ---- Test accuracy: 0.9805999994277954"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "3UWZMX4GiW_t"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 37.7194 - accuracy: 0.9806\n",
      "Test loss: 37.7193717956543\n",
      "Test accuracy: 0.9805999994277954\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "score = model2.evaluate(test_images, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DugttsffiXza"
   },
   "source": [
    "### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1667345674787,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "dMUfG8mfiXQw",
    "outputId": "e58ff701-1c60-400d-bef7-b19239c64801"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_20 (Conv2D)          (None, 26, 26, 4)         40        \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 24, 24, 8)         296       \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 22, 22, 12)        876       \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 20, 20, 16)        1744      \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 18, 18, 20)        2900      \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 16, 16, 24)        4344      \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 14, 14, 20)        4340      \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 12, 12, 16)        2896      \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 10, 10, 12)        1740      \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 8, 8, 8)           872       \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,178\n",
      "Trainable params: 25,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Sequential Model\n",
    "model3 = keras.models.Sequential([\n",
    "        keras.Input(shape=(28,28,1)),\n",
    "        keras.layers.Conv2D(4, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(12, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(20, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(24, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(20, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(12, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(\n",
    "    optimizer='RMSprop',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "K.set_value(model3.optimizer.learning_rate, 0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 12s 12ms/step - loss: 0.0060 - accuracy: 0.9984\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0044 - accuracy: 0.9990\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0042 - accuracy: 0.9990\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0045 - accuracy: 0.9988\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 14s 15ms/step - loss: 0.0044 - accuracy: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6df8cbf70>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model.\n",
    "model3.fit(\n",
    "    train_images,\n",
    "    train_labels, \n",
    "    batch_size=64,\n",
    "    epochs=5, \n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will summarize the results based on the optimizer method\n",
    "\n",
    "##### Adam:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 7.333022594451904 ---- Test accuracy: 0.9681000113487244\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 18.73436164855957 ---- Test accuracy: 0.9402999877929688\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 13.888640403747559 ---- Test accuracy: 0.9501000046730042\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 18.489398956298828 ---- Test accuracy: 0.9591000080108643\n",
    "\n",
    "\n",
    "##### SGD:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 15.506414413452148 ---- Test accuracy: 0.968500018119812\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 15.83298397064209 ---- Test accuracy: 0.9690999984741211\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 16.004711151123047 ---- Test accuracy: 0.9693999886512756\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 16.097017288208008 ---- Test accuracy: 0.9696000218391418\n",
    "\n",
    "\n",
    "##### RMSProp:\n",
    "For this method I tried different combinations of batch size and learning rate. These were the results:\n",
    "\n",
    "##### learning rate = 0.001\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 54.20248794555664 ---- Test accuracy: 0.8810999989509583\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 36.41796875 ---- Test accuracy: 0.9447000026702881\n",
    "\n",
    "\n",
    "##### learning rate = 0.0005\n",
    "\n",
    "batch_size = 32, epochs = 5 : Test loss: 69.07653045654297 ---- Test accuracy: 0.9448000192642212\n",
    "\n",
    "batch_size = 64, epochs = 5 : Test loss: 76.99116516113281 ---- Test accuracy: 0.9491000175476074"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 76.9912 - accuracy: 0.9491\n",
      "Test loss: 76.99116516113281\n",
      "Test accuracy: 0.9491000175476074\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "score = model3.evaluate(test_images, test_labels)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XSXJwtX28smS"
   },
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6561,
     "status": "ok",
     "timestamp": 1667247104525,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "tE4cYwXn8mLx",
    "outputId": "53d67ff4-a382-43a0-82ab-499e98d52ad1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)\n",
    "\n",
    "x_train = x_train / 255.0\n",
    "tf.keras.utils.to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "drU9V5u38mrc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_30 (Conv2D)          (None, 28, 28, 6)         456       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 14, 14, 6)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 10, 10, 16)        2416      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 1, 1, 120)         48120     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 120)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 62,006\n",
      "Trainable params: 62,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=6, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(keras.layers.Conv2D(filters=16, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "model.add(keras.layers.Conv2D(filters=120, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=84, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=10, activation = 'softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "K.set_value(model.optimizer.learning_rate, 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.9831 - accuracy: 0.2828\n",
      "Epoch 2/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.6646 - accuracy: 0.4028\n",
      "Epoch 3/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.5702 - accuracy: 0.4350\n",
      "Epoch 4/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.5150 - accuracy: 0.4522\n",
      "Epoch 5/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.4765 - accuracy: 0.4691\n",
      "Epoch 6/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.4457 - accuracy: 0.4818\n",
      "Epoch 7/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.4188 - accuracy: 0.4911\n",
      "Epoch 8/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.3981 - accuracy: 0.4990\n",
      "Epoch 9/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.3799 - accuracy: 0.5080\n",
      "Epoch 10/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.3595 - accuracy: 0.5135\n",
      "Epoch 11/25\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 1.3440 - accuracy: 0.5211\n",
      "Epoch 12/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.3265 - accuracy: 0.5278\n",
      "Epoch 13/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.3125 - accuracy: 0.5337\n",
      "Epoch 14/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.2993 - accuracy: 0.5377\n",
      "Epoch 15/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.2845 - accuracy: 0.5442\n",
      "Epoch 16/25\n",
      "782/782 [==============================] - 3s 4ms/step - loss: 1.2711 - accuracy: 0.5488\n",
      "Epoch 17/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2589 - accuracy: 0.5520\n",
      "Epoch 18/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2472 - accuracy: 0.5570\n",
      "Epoch 19/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2365 - accuracy: 0.5612\n",
      "Epoch 20/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2246 - accuracy: 0.5662\n",
      "Epoch 21/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2140 - accuracy: 0.5694\n",
      "Epoch 22/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.2044 - accuracy: 0.5725\n",
      "Epoch 23/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1929 - accuracy: 0.5781\n",
      "Epoch 24/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1834 - accuracy: 0.5807\n",
      "Epoch 25/25\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 1.1756 - accuracy: 0.5861\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6df8f5300>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train, \n",
    "    batch_size=64,\n",
    "    epochs=25, \n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 276.4186 - accuracy: 0.4236\n",
      "Test loss: 276.41864013671875\n",
      "Test accuracy: 0.4235999882221222\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the effect of learning rate on the training process? Which performed best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "49/49 [==============================] - 2s 35ms/step - loss: 1.1495 - accuracy: 0.5944\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 1.1437 - accuracy: 0.5971\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 2s 39ms/step - loss: 1.1409 - accuracy: 0.5996\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.1375 - accuracy: 0.5996\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1382 - accuracy: 0.5999\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.1352 - accuracy: 0.6018\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.1323 - accuracy: 0.6014\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.1296 - accuracy: 0.6036\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.1283 - accuracy: 0.6033\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.1245 - accuracy: 0.6051\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.1257 - accuracy: 0.6032\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.1214 - accuracy: 0.6048\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1189 - accuracy: 0.6072\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.1197 - accuracy: 0.6075\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.1156 - accuracy: 0.6080\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.1124 - accuracy: 0.6086\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.1123 - accuracy: 0.6081\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.1112 - accuracy: 0.6092\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.1080 - accuracy: 0.6097\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.1076 - accuracy: 0.6096\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.1053 - accuracy: 0.6110\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.1026 - accuracy: 0.6133\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.1002 - accuracy: 0.6131\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.1000 - accuracy: 0.6144\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0976 - accuracy: 0.6143\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 286.6805 - accuracy: 0.4326\n",
      "Epoch 1/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.1058 - accuracy: 0.6121\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0966 - accuracy: 0.6164\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0930 - accuracy: 0.6152\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0941 - accuracy: 0.6148\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0923 - accuracy: 0.6171\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0839 - accuracy: 0.6188\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0836 - accuracy: 0.6202\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0805 - accuracy: 0.6206\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0800 - accuracy: 0.6206\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0744 - accuracy: 0.6235\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0705 - accuracy: 0.6235\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.0694 - accuracy: 0.6249\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0670 - accuracy: 0.6262\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0667 - accuracy: 0.6261\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0621 - accuracy: 0.6267\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0575 - accuracy: 0.6289\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0575 - accuracy: 0.6299\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.0537 - accuracy: 0.6305\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0517 - accuracy: 0.6308\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.0469 - accuracy: 0.6331\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.0498 - accuracy: 0.6344\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.0453 - accuracy: 0.6349\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0382 - accuracy: 0.6369\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 1.0402 - accuracy: 0.6357\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0338 - accuracy: 0.6378\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 317.2761 - accuracy: 0.4245\n",
      "Epoch 1/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0553 - accuracy: 0.6296\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0309 - accuracy: 0.6394\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0334 - accuracy: 0.6391\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0274 - accuracy: 0.6413\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 1.0250 - accuracy: 0.6427\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0214 - accuracy: 0.6424\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0185 - accuracy: 0.6444\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.0159 - accuracy: 0.6461\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 2s 51ms/step - loss: 1.0175 - accuracy: 0.6446\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 1.0115 - accuracy: 0.6480\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 1.0085 - accuracy: 0.6470\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 1.0064 - accuracy: 0.6499\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0038 - accuracy: 0.6493\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 1.0021 - accuracy: 0.6497\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 1.0011 - accuracy: 0.6494\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9958 - accuracy: 0.6532\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 2s 50ms/step - loss: 0.9913 - accuracy: 0.6543\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9904 - accuracy: 0.6565\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9842 - accuracy: 0.6583\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9803 - accuracy: 0.6587\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9768 - accuracy: 0.6606\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9775 - accuracy: 0.6589\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9742 - accuracy: 0.6611\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9710 - accuracy: 0.6634\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9680 - accuracy: 0.6630\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 346.6735 - accuracy: 0.4207\n",
      "Epoch 1/25\n",
      "49/49 [==============================] - 3s 47ms/step - loss: 1.0186 - accuracy: 0.6463\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9643 - accuracy: 0.6651\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9627 - accuracy: 0.6667\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9591 - accuracy: 0.6672\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 [==============================] - 2s 49ms/step - loss: 0.9590 - accuracy: 0.6674\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9565 - accuracy: 0.6682\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9539 - accuracy: 0.6677\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9484 - accuracy: 0.6701\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9517 - accuracy: 0.6679\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9493 - accuracy: 0.6694\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9461 - accuracy: 0.6709\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9405 - accuracy: 0.6731\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9404 - accuracy: 0.6730\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9334 - accuracy: 0.6765\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.9292 - accuracy: 0.6785\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.9330 - accuracy: 0.6752\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9279 - accuracy: 0.6782\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9239 - accuracy: 0.6804\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9217 - accuracy: 0.6803\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9136 - accuracy: 0.6833\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9085 - accuracy: 0.6867\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.9125 - accuracy: 0.6828\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.9090 - accuracy: 0.6849\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9063 - accuracy: 0.6860\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.9044 - accuracy: 0.6857\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 324.8466 - accuracy: 0.4457\n",
      "Epoch 1/25\n",
      "49/49 [==============================] - 3s 45ms/step - loss: 0.9697 - accuracy: 0.6629\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8969 - accuracy: 0.6907\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8991 - accuracy: 0.6881\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8983 - accuracy: 0.6887\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.9006 - accuracy: 0.6876\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.8947 - accuracy: 0.6899\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8855 - accuracy: 0.6935\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8831 - accuracy: 0.6940\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.8831 - accuracy: 0.6935\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8889 - accuracy: 0.6901\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8779 - accuracy: 0.6965\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8752 - accuracy: 0.6972\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.8760 - accuracy: 0.6967\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8711 - accuracy: 0.6970\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8630 - accuracy: 0.7020\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8640 - accuracy: 0.7001\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8713 - accuracy: 0.6973\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8581 - accuracy: 0.7029\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8572 - accuracy: 0.7029\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8502 - accuracy: 0.7066\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8516 - accuracy: 0.7051\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8512 - accuracy: 0.7042\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8493 - accuracy: 0.7067\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8418 - accuracy: 0.7098\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8370 - accuracy: 0.7099\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 341.9101 - accuracy: 0.4411\n",
      "Epoch 1/25\n",
      "49/49 [==============================] - 3s 45ms/step - loss: 0.9276 - accuracy: 0.6809\n",
      "Epoch 2/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8282 - accuracy: 0.7135\n",
      "Epoch 3/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8380 - accuracy: 0.7091\n",
      "Epoch 4/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8324 - accuracy: 0.7115\n",
      "Epoch 5/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8298 - accuracy: 0.7123\n",
      "Epoch 6/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8309 - accuracy: 0.7110\n",
      "Epoch 7/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8210 - accuracy: 0.7161\n",
      "Epoch 8/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8245 - accuracy: 0.7156\n",
      "Epoch 9/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8331 - accuracy: 0.7115\n",
      "Epoch 10/25\n",
      "49/49 [==============================] - 3s 52ms/step - loss: 0.8239 - accuracy: 0.7135\n",
      "Epoch 11/25\n",
      "49/49 [==============================] - 2s 43ms/step - loss: 0.8142 - accuracy: 0.7190\n",
      "Epoch 12/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.8079 - accuracy: 0.7209\n",
      "Epoch 13/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.8030 - accuracy: 0.7246\n",
      "Epoch 14/25\n",
      "49/49 [==============================] - 2s 44ms/step - loss: 0.8107 - accuracy: 0.7207\n",
      "Epoch 15/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.8002 - accuracy: 0.7243\n",
      "Epoch 16/25\n",
      "49/49 [==============================] - 2s 47ms/step - loss: 0.7987 - accuracy: 0.7243\n",
      "Epoch 17/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.8008 - accuracy: 0.7244\n",
      "Epoch 18/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.7883 - accuracy: 0.7271\n",
      "Epoch 19/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.7882 - accuracy: 0.7277\n",
      "Epoch 20/25\n",
      "49/49 [==============================] - 2s 45ms/step - loss: 0.7902 - accuracy: 0.7275\n",
      "Epoch 21/25\n",
      "49/49 [==============================] - 2s 49ms/step - loss: 0.7853 - accuracy: 0.7298\n",
      "Epoch 22/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.7759 - accuracy: 0.7340\n",
      "Epoch 23/25\n",
      "49/49 [==============================] - 2s 48ms/step - loss: 0.7750 - accuracy: 0.7337\n",
      "Epoch 24/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.7798 - accuracy: 0.7315\n",
      "Epoch 25/25\n",
      "49/49 [==============================] - 2s 46ms/step - loss: 0.7741 - accuracy: 0.7342\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 374.1581 - accuracy: 0.4506\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "res_loss = np.zeros(n)\n",
    "res_acc = np.zeros(n)\n",
    "alphas = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    alpha = 0.0001*(i+1)\n",
    "    alphas[i] = alpha\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    K.set_value(model.optimizer.learning_rate, alpha)\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    # Train the model.\n",
    "    model.fit(x_train, y_train, batch_size=1024,epochs=25, callbacks=[tensorboard_callback])\n",
    "    # Evaluate\n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    res_loss[i] = score[0]\n",
    "    res_acc[i] = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas,res_loss)\n",
    "plt.title(\"Results\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas,res_acc)\n",
    "plt.title(\"Results\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"learning rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the effect of batch size on the training process? Which performed best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "res_loss2 = np.zeros(n)\n",
    "res_acc2 = np.zeros(n)\n",
    "batchs = np.zeros(n)\n",
    "\n",
    "for i in range(n):\n",
    "    batch = 10*(i+1)\n",
    "    batchs[i] = batch\n",
    "    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    # Define the Keras TensorBoard callback.\n",
    "    logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "    # Train the model.\n",
    "    model.fit(x_train, y_train, batch_size=batch,epochs=25, callbacks=[tensorboard_callback])\n",
    "    # Evaluate\n",
    "    score = model.evaluate(x_test, y_test)\n",
    "    res_loss2[i] = score[0]\n",
    "    res_acc2[i] = score[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(batch,res_loss2)\n",
    "plt.title(\"Results\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(batch,res_acc2)\n",
    "plt.title(\"Results\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.xlabel(\"learning rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try different hyperparameters to obtain the best accuracy on the test set. What is your best performance and what were the hyperparameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement an equivalent feed forward network for the same task with each hidden layer containing the same number of neurons as the number of filters in each convolution layer. Use the Adam optimizer to train your network on the CIFAR-10 dataset for a fixed set of 25 epochs. Compare its performance with your LeNet implementation based on the following questions: \n",
    "\n",
    "a. What is its performance?\n",
    "b. How many parameters are there in this network compared to the LeNet\n",
    "implementation? Are they worth it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFJ6DFl38eSU"
   },
   "source": [
    "# Question 3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euz1IZnM9Cke"
   },
   "source": [
    "### What are the dimensions of the input and the kernel (or filter)? How many parameters are there in the kernel f?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1667239043031,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "NbsyxPcu8jKK",
    "outputId": "cd1eba0b-d658-444b-a84e-8e014ffa2f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth of input/kernel: 1\n",
      "Input dimensions:  (6, 6)\n",
      "Kernel dimensions:  (3, 3)\n",
      "Parameters in kernel:  10\n"
     ]
    }
   ],
   "source": [
    "# Input \n",
    "matrix = np.array([[7,5,0,0,3,2],[6,4,5,1,4,8],[9,0,2,2,5,4],[6,3,4,7,9,8],[5,7,5,6,9,0],[7,9,0,8,2,3]])\n",
    "W1,H1 = np.shape(matrix)\n",
    "C = 1\n",
    "print(\"Depth of input/kernel:\", C)\n",
    "\n",
    "# filter\n",
    "kernel = np.array([[1,0,-1],[2,0,-2],[1,0,-1]])\n",
    "F = np.shape(kernel)[0]\n",
    "\n",
    "print(\"Input dimensions: \",np.shape(matrix))\n",
    "print(\"Kernel dimensions: \",np.shape(kernel))\n",
    "\n",
    "##Parameters in kernel \n",
    "par = F*F*C + 1\n",
    "print(\"Parameters in kernel: \",par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olr0VmugDnia"
   },
   "source": [
    "### What is the output activation map when you apply the convolutional operation using the filter f on the input X without padding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1667239044668,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "obts4s9ZBFr9",
    "outputId": "060472bf-db00-4f82-eb46-02df4a4d6296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output dimensions: (4.0, 4.0, 1)\n",
      "Output:  [[ 16   9  -4 -18]\n",
      " [ 17  -5 -10 -12]\n",
      " [ 11  -9 -17   2]\n",
      " [  9  -1 -15  16]]\n"
     ]
    }
   ],
   "source": [
    "## stride and padding\n",
    "S, P = (1,0)\n",
    "W2 = (W1-F+2*P)/S + 1\n",
    "H2 = (H1-F+2*P)/S + 1\n",
    "out_dim = (W2,H2,C)\n",
    "\n",
    "print(\"Output dimensions:\",out_dim)\n",
    "\n",
    "#convolutional layer\n",
    "def conv2d(mat, krn):\n",
    "\n",
    "    is0, is1, ks0, ks1 = *mat.shape, *krn.shape\n",
    "    rs0, rs1 = is0 - ks0 + 1, is1 - ks1 + 1\n",
    "    res = np.zeros((rs0, rs1), dtype = krn.dtype)\n",
    "    \n",
    "    for i in range(rs0):\n",
    "        for j in range(rs1):\n",
    "            res[i, j] = (krn * mat[i : i + ks0, j : j + ks1]).sum()\n",
    "            \n",
    "    return res\n",
    "##output    \n",
    "output = conv2d(matrix,kernel)\n",
    "print(\"Output: \",output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yuQe5RxhIv7Q"
   },
   "source": [
    "### What is the output when you apply a max-pooling operation on the output from the previous question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1667239046697,
     "user": {
      "displayName": "Alberto Navarro",
      "userId": "07299865193384909733"
     },
     "user_tz": 300
    },
    "id": "ygPvJQemITjD",
    "outputId": "4dddf84c-ab48-48c1-a11e-839bbc3a216c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pooling output:  [[17 -4]\n",
      " [11 16]]\n"
     ]
    }
   ],
   "source": [
    "import skimage.measure\n",
    "## Using a 2x2 filter with stride 2\n",
    "max_pool_out = skimage.measure.block_reduce(output, (2,2), np.max)\n",
    "print(\"Max pooling output: \",max_pool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukKPAzp3Kr3y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO2q37OvAeKaV/CREHW6sb/",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
